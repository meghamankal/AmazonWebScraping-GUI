{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PySimpleGUI\n",
    "!pip install pandas\n",
    "!pip install selenium\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to enable chrome driver \n",
    "#based on your chrome browser version, install chrome driver\n",
    "#click on help in your chrome browser, \n",
    "#check the version and install the supporting version\n",
    "\n",
    "#various available versions: 2.38, 2.45.2, 2.45.3, 2.46, 78.0.3904.11, 78.0.3904.70, \n",
    "#79.0.3945.16, 79.0.3945.36, 80.0.3987.16, 81.0.4044.20, \n",
    "#81.0.4044.69, 83.0.4103.14, 83.0.4103.39, 84.0.4147.30, \n",
    "#85.0.4183.38, 85.0.4183.83, 85.0.4183.87, 86.0.4240.22, \n",
    "#87.0.4280.20, 87.0.4280.88, 88.0.4324.27, 88.0.4324.96, \n",
    "#89.0.4389.23, 90.0.4430.24, 91.0.4472.1\n",
    "\n",
    "!pip install chromedriver-py==90.0.4430.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "from chromedriver_py import binary_path\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "\n",
    "sg.theme(\"SystemDefault\")\n",
    "\n",
    "def scraping(url):\n",
    "    driver = webdriver.Chrome(executable_path=binary_path)\n",
    "    driver.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    \n",
    "    x = soup.find(\"div\",{\"id\":\"filter-info-section\"})\n",
    "    value = x.get_text()\n",
    "    \n",
    "    r = \"\"\n",
    "    \n",
    "    for i in range(0,len(value)):\n",
    "        if value[i] == \"|\":\n",
    "            for i in range(i+1,len(value)):\n",
    "                r = r+value[i]\n",
    "\n",
    "    r = r.replace(',','')\n",
    "\n",
    "    n = re.findall(r'\\d+', r)\n",
    "\n",
    "    last = (int(n[0])//10) + 1 \n",
    "\n",
    "    if (int(n[0])%10) !=0:\n",
    "        last = last+ 1 \n",
    "    \n",
    "    customers = []\n",
    "    titles = []\n",
    "    reviews = []\n",
    "    ratings = []\n",
    "\n",
    "    for page in range(1,last):\n",
    "        if page == 1:\n",
    "            driver.get(url)\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    \n",
    "        else:\n",
    "        \n",
    "            l = \"\"\n",
    "            x = soup.find('li',{'class':'a-last'})\n",
    "            for link in x.findAll('a', attrs={'href':re.compile('/')}):\n",
    "                l = link.get('href')\n",
    "        \n",
    "            url = \"https://www.amazon.in\" + l\n",
    "            \n",
    "            driver.get(url.format(page,page))\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "        \n",
    "        \n",
    "        #retirving customer names\n",
    "        names =soup.find_all('span',{'class':'a-profile-name'})\n",
    "\n",
    "   \n",
    "        for i in range(2,len(names)):\n",
    "            customers.append(names[i].get_text())\n",
    "        \n",
    "        #review titles\n",
    "        title = soup.find_all('a',{'data-hook':'review-title'})\n",
    "        \n",
    "        for i in range(0,len(title)):\n",
    "            x = title[i].get_text()\n",
    "            titles.append(x[1:len(x)-1])\n",
    "        \n",
    "        #review given by the customer\n",
    "        review = soup.find_all(\"span\",{\"data-hook\":\"review-body\"})\n",
    "\n",
    "        for i in range(0,len(review)):\n",
    "            x = review[i].get_text()\n",
    "            reviews.append(x[4:len(x)-2])\n",
    "        \n",
    "        #rating given by the customer\n",
    "        rating = soup.find_all('i',{'class':'review-rating'})\n",
    "\n",
    "        for i in range(2,len(rating)):\n",
    "            x = rating[i].get_text()\n",
    "            ratings.append(x[0:3])\n",
    "        \n",
    "    driver.close()\n",
    "    \n",
    "    output[\"Customer Name\"] = customers\n",
    "    output[\"Review Title\"] = titles\n",
    "    output[\"Review\"] = reviews\n",
    "    output[\"Rating\"] = ratings\n",
    "    \n",
    "    return r\n",
    "    \n",
    "output = pd.DataFrame(columns = [\"Customer Name\",'Review Title', 'Review', 'Rating'])\n",
    "\n",
    "layout = [[sg.Text(\"Welcome to Amazon Web Scraping Application\",justification = \"center\",size = (50,1),font=(\"Helvetica\", 15))],\n",
    "          [sg.Text(\"\")],\n",
    "          [sg.Text(\"NOTE: Please click on 'See all reviews' button of a particular product and paste the link here!\",font=(\"Helvetica\", 11))],\n",
    "          [sg.Text(\"          \"),sg.InputText(),sg.Button('Scrap Reviews')],\n",
    "          [sg.Text(\"          \"),sg.Text(\"\",size = (50,1),key = \"result1\",font=(\"Helvetica\", 10))],\n",
    "          [sg.Text(\"\")],\n",
    "          [sg.Text(\"Please enter the file name to be saved\",font=(\"Helvetica\", 11))],\n",
    "          [sg.Text(\"          \"),sg.InputText()],\n",
    "          [sg.Text(\"          \"),sg.Button('Save As CSV'), sg.Button('Save As Excel')],\n",
    "          [sg.Text(\"          \"),sg.Text(\"\",size = (50,1),key = \"result2\",font=(\"Helvetica\", 10))]\n",
    "         ]\n",
    "\n",
    "window = sg.Window(\"Web Scraping\",layout)\n",
    "\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    \n",
    "    if event in (sg.WIN_CLOSED, 'Exit'):\n",
    "        break\n",
    "    if event == sg.WIN_CLOSED or event == 'Exit':\n",
    "        break\n",
    "    \n",
    "    if event == \"Scrap Reviews\":\n",
    "        out = scraping(values[0])\n",
    "        s = \"Successfully Collected \" + out\n",
    "        window[\"result1\"].Update(s)\n",
    "    \n",
    "    if event == \"Save As CSV\":\n",
    "        filename = values[1] + \".csv\"\n",
    "        output.to_csv(filename)\n",
    "        f = filename + \" saved successfully at the ipynb file location!\"\n",
    "        window[\"result2\"].Update(f)\n",
    "    \n",
    "    if event == \"Save As Excel\":\n",
    "        filename = values[1] + \".xlsx\"\n",
    "        output.to_excel(filename)\n",
    "        f = filename + \" saved successfully at the ipynb file location!\"\n",
    "        window[\"result2\"].Update(f)\n",
    "            \n",
    "window.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
